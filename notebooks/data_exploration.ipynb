{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3941d5-2eb7-4d9a-8da9-1132f676f38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from context import sniff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774dbc98-02ce-4435-8695-0466fb54620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "import pypandoc\n",
    "import spacy\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1a1f72-1192-4f66-b908-566e841c0df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_txt_competence_profile(file_path: Path) -> str:\n",
    "    with file_path.open('r') as file_handle:\n",
    "        return file_handle.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d988ba-604f-414e-9072-4a8e7229cba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = Path('/home/matt/competence_profiles/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b841952c-8922-4e17-a2b6-096847a03df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_short_names_of_files(path_to_folder: Path) -> list[str]:\n",
    "    \"\"\"Given all the competence profile files at the path_to_folder location, extract all ipt short names from it.\"\"\"\n",
    "    \n",
    "    file_paths = path_to_folder.glob('Competence Profile_???.docx')\n",
    "    \n",
    "    def extract_shortname_from_file_name(file_name: str) -> str:\n",
    "        return file_name.split('_')[1].split('.')[0]\n",
    "    \n",
    "    short_names = [extract_shortname_from_file_name(path.name) for path in file_paths]\n",
    "    return list(short_names)\n",
    "\n",
    "def convert_competence_profile_to_plain_text(competence_profile_file_path: Path) -> str:\n",
    "    \"\"\"This will convert a .docx competence profile to simple text and removes weird characters originating from tables.\"\"\"\n",
    "    \n",
    "    txt = pypandoc.convert_file(str(competence_profile_file_path), 'org')\n",
    "    txt = txt.split('\\n', 1)[1]  # remove first line (comes from profile image)\n",
    "    \n",
    "    # The following filters are necessary since there are a lot of weird symbols due to the tables in the word document in the text.\n",
    "    txt = txt.replace('|', ' ')\n",
    "    txt = txt.replace('-', ' ')\n",
    "    txt = txt.replace('=', ' ')\n",
    "    txt = txt.replace('+', ' ')\n",
    "    txt = txt.replace('*', ' ')\n",
    "    txt = txt.replace('/', ' ')\n",
    "    txt = txt.replace('# begin_quote', ' ')\n",
    "    txt = txt.replace('# end_quote', ' ')\n",
    "    txt = txt.replace('\\n', ' ')\n",
    "    txt = txt.strip()\n",
    "    return txt\n",
    "    \n",
    "def extract_all_words(competence_profile_plain_txt: str) -> list[str]:\n",
    "    \"\"\"\"Given plain text, extract all the words contained in this unstructured text.\"\"\"\n",
    "    \n",
    "    regex_pattern = r\"\\(\\d\\s+('?\\w+)\"\n",
    "    return re.findall(\"[a-zA-Z\\-\\.'/]+\", competence_profile_plain_txt)\n",
    "\n",
    "def extract_core_competence_words(competence_profile_words: list[str]) -> list[str]:\n",
    "    \"\"\"This will filter the input words such that only words after 'Kernkompetenzen' and before 'ipt Projekte' will remain.\"\"\"\n",
    "    \n",
    "    arrived_at_core_competences = False\n",
    "    core_competence_words = []\n",
    "    for idx, word in enumerate(competence_profile_words):\n",
    "        if word == 'Kernkompetenzen':\n",
    "            arrived_at_core_competences = True\n",
    "            continue\n",
    "        if arrived_at_core_competences:\n",
    "            if word == 'ipt' and competence_profile_words[idx + 1] == 'Projekte':\n",
    "                break\n",
    "            else:\n",
    "                core_competence_words.append(word)\n",
    "    return core_competence_words\n",
    "\n",
    "def to_lower(words: list[str]) -> list[str]:\n",
    "    return [word for word in words]\n",
    "\n",
    "def filter_out_stop_words(words: list[str]) -> list[str]:\n",
    "    sp = spacy.load('de_core_news_sm')\n",
    "    stop_words = sp.Defaults.stop_words\n",
    "    return [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "def build_competence_dict(base_path: Path) -> dict[str, list[str]]:\n",
    "    \"\"\"\n",
    "    Given a base_path pointing to a folder were all the .docx competence profiles reside, build a a competence_dict.\n",
    "    \n",
    "    The competence_dict's structure is as follows\n",
    "    {'ABC': ['masta_skill', 'epic_skill'], ...}\n",
    "    \"\"\"\n",
    "    short_names = get_all_short_names_of_files(BASE_PATH)\n",
    "    competence_dict = {short_name: [] for short_name in short_names}\n",
    "\n",
    "    for idx, short_name in tqdm(enumerate(short_names), total=len(short_names)):\n",
    "        file_path = BASE_PATH / f'Competence Profile_{short_name}.docx'\n",
    "        txt = convert_competence_profile_to_plain_text(file_path)\n",
    "        words = extract_all_words(txt)\n",
    "        core_competence_words = extract_core_competence_words(words)\n",
    "        core_competence_words = filter_out_stop_words(core_competence_words)\n",
    "        core_competence_words = to_lower(core_competence_words)\n",
    "        competence_dict[short_name] = core_competence_words\n",
    "    \n",
    "    return competence_dict\n",
    "\n",
    "def generate_word_cloud_from_competence_dict(competence_dict: dict) -> None:\n",
    "    \"\"\"Given the competence_dict this will generate and store a word cloud with word sizes weighted on occurrence.\"\"\"\n",
    "    \n",
    "    HARCODED_FILTER_WORDS = ['Software', 'Architektur', 'Technologien', 'f']  # These sort of clutter everythin\n",
    "    all_words = list(itertools.chain(*competence_dict.values())) \n",
    "    \n",
    "    all_words = [word for word in all_words if word not in HARCODED_FILTER_WORDS]\n",
    "    wordcloud = WordCloud(width = 1600, height = 1000,\n",
    "                background_color ='white',\n",
    "                min_font_size = 10).generate(' '.join(all_words))\n",
    " \n",
    "    # plot the WordCloud image                      \n",
    "    plt.figure(figsize = (10, 10), facecolor = None)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad = 0)\n",
    "\n",
    "    plt.savefig('ipt_competence_word_cloud.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c349b35-3195-4928-87c7-2cbbeb551890",
   "metadata": {},
   "source": [
    "# Executable Code Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf37126-928c-46ba-95e7-61d8d5281411",
   "metadata": {},
   "outputs": [],
   "source": [
    "competence_dict = build_competence_dict(BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e6787f-db00-429d-b967-765dfae28503",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_word_cloud_from_competence_dict(competence_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
